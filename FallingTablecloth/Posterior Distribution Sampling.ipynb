{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Background\n",
    "\n",
    "Suppose we have the following function or forward model,\n",
    "\n",
    "$$G(\\mathbf{x},\\mathbf{m}) = m_0 e^{m_1\\mathbf{x}} + m_2 \\mathbf{x} e^{m_3\\mathbf{x}}$$\n",
    "\n",
    "where $\\mathbf{x}$ and $\\mathbf{m}$ are vectors and the operations are element-wise, as you would expect `numpy` to do on arrays. That is to say, for $N$ length array $\\mathbf{x}$, $G$ will have $N$ values. Also assume we have data set $\\mathbf{d} = (d_0,d_1,d_2,...)$ that can explained (or 'fit') by this function. We would like to know the values of the parameters $\\mathbf{m} = (m_0,m_1,m_2,m_3)$ that best explain the data using the function $G(x,\\mathbf{m})$. Further, we would like to know the distribution of those parameters $\\mathbf{m}$.\n",
    "\n",
    "For the purpose of experimentation, let us assume that we know the true values of $\\mathbf{m_t}$ are $(1.0,-0.5,1.0,-0.75)$. Further suppose the 'data', $\\mathbf{d}$ can be generated by creating a vector $\\mathbf{x}$, and evaluating $G(\\mathbf{x},\\mathbf{m_t})$ and then adding measurement noise in the form of $N(0,\\sigma)$. Here the $\\mathbf{x}$ should be 25 equally spaced values on the interval [1,7]. The data noise should be characterized by $\\sigma = $ 0.01 where $N(0,\\sigma)$ is a Gaussian with 0 mean and standard deviation $\\sigma$. Perhaps you'll find this easier to understand in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.05841261 0.93136895 0.80740004 0.68748788 0.60777642 0.50670715\n",
      " 0.43889186 0.37918262 0.33767804 0.28316015 0.24459221 0.20544717\n",
      " 0.19491684 0.1648118  0.14951262 0.10318167 0.11726088 0.08574999\n",
      " 0.08178144 0.06609646 0.0522403  0.02411202 0.04220553 0.03710124\n",
      " 0.03293079]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def G(x,m):\n",
    "    \"\"\" you can do this, write the function\"\"\"\n",
    "    x = m[0] *np.exp(m[1]*x) + m[2] *np.exp(m[3]*x)\n",
    "    return x\n",
    "\n",
    "sigma = 0.01\n",
    "x = np.linspace(1,7,25)\n",
    "m_t = np.array([1,-.5,1,-.75])  # These are the true values that we will attempt to recover\n",
    "\n",
    "d = G(x,m_t) + np.random.randn(x.size) * sigma  # The 'data' which we generate with a noise signal\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you should now know, the sampling will require a so-called likelihood function, or the probability of encountering the data, given some set of $\\mathbf{m}$. If we assume errors are Gaussian, or normally distributed, as we did for the noise on the observations, then the likelihood will be\n",
    "\n",
    "$$q(\\mathbf{d} | \\mathbf{m}) = \\prod_{i=1}^n e^{-\\frac{1}{2}(d_i - G(x_i,\\mathbf{m}))^2 / \\sigma^2}$$\n",
    "\n",
    "This is great, but we are taking a product of many small numbers here and the potential for underflow is real. So, we take the natural $\\log$ of this:\n",
    "\n",
    "$$\\log(q(\\mathbf{d}|\\mathbf{m})) = -\\frac{1}{2} \\sum_{i=1}^n (d_i - G(x_i,\\mathbf{m})^2/\\sigma^2$$\n",
    "\n",
    "The acceptance rates are in general\n",
    "\n",
    "$$\\alpha(\\mathbf{m_p},\\mathbf{m}) = \\min\\left(1,\\frac{q(\\mathbf{d} | \\mathbf{m_p})}{q(\\mathbf{d} | \\mathbf{m})}\\right)$$\n",
    "\n",
    "Taking the $\\log$ of the acceptance rates gives\n",
    "\n",
    "$$ \\log(\\alpha) = \\min(0,\\log(q(\\mathbf{d}|\\mathbf{m_p})) -\\log(q(\\mathbf{d}|\\mathbf{m})))$$\n",
    "\n",
    "where $\\mathbf{m}_p$ is the proposed $\\mathbf{m}$. Don't forget that because the acceptance rate is the $\\log$ of liklihood calculations, then we must take the $\\log$ of the uniform random number from the interval [0,1] as well.\n",
    "\n",
    "### Problem ###\n",
    "\n",
    "Determine distributions for the parameters $\\mathbf{m}$ by using MCMC to sample the posterior distributions. Use uniformly distributed random numbers for $\\mathbf{m}_o$, the intial values of the parameters: $m_0 \\in [0,2]$, $m_1 \\in [-1,0]$, $m_2 \\in [0,2]$, $m_3 \\in [-1,0]$. Do a \"burn-in\" of 10,000 samples, followed by a chain of 400,000 samples. In each MCMC step, generate a proposal by adding normally distributed random numbers with a mean of zero and standard deviation of 0.005 to $\\mathbf{m}$.\n",
    "\n",
    "Once the simulation is complete, resample the MCMC chain by taking only every 1000th set of $\\mathbf{m}$ from the full chain. Plot histograms for each variable, and compute means and standard deviations on the resulting distributions. How close are you to 'truth'?\n",
    "\n",
    "Consider the following question: would it be better to double the size of the data set, or halve the errors in the data?\n",
    "\n",
    "#### Hints ####\n",
    "Syntacitically, the `scipy.stats.norm` is often cleaner than `numpy.random.randn` for generating random numbers.\n",
    "\n",
    "Check and recheck your formula for the likelihood. It's critical but easy to make mistakes on parentheses.\n",
    "\n",
    "It takes a long time to run 400,000 samples. For testing just do 100,000. You'll get the sense of things from that.\n",
    "\n",
    "The acceptance rate is around 40%. Compute it and check against this value to see if you're doing things right.\n",
    "\n",
    "Truthfully, I had a hard time getting this to work right. The forward model is very sensitive to small changes. Don't kill yourself on this assignment. Something that looks close will grade well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Algorythm\n",
    "- Begin with mu_0 - guess at peramitor\n",
    "\n",
    "- Generate a proposal\n",
    "    mu_p = mu_n + mu_0\n",
    "\n",
    "- find log(alpha)\n",
    "- find w = log(rand(0,1))\n",
    "    - if w < log (alpha) ACCEPT\n",
    "    - else: mu_n+1=mu_n0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-82-a1ba954c52d0>:23: RuntimeWarning: invalid value encountered in log\n",
      "  if np.log(r)< a:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burn In Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def prob(d,m,x,sigma):\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(len(x)):\n",
    "\n",
    "        sum += ((d[i]-G(x[i],m))**2/sigma**2)\n",
    "    sum *= .5\n",
    "    return sum\n",
    "\n",
    "def acceptance_rate(p1,p2):\n",
    "    return np.min([0. , np.log(p1)-np.log(p2)])\n",
    "\n",
    "\n",
    "\n",
    "def mcmc(d,mu,x,sigma):\n",
    "    global rate\n",
    "    mu_p =  [mu[0]+np.random.randn()*sigma,mu[1]+np.random.randn()*sigma,mu[2]+np.random.randn()*sigma,mu[3]+np.random.randn()*sigma]\n",
    "    p1 = prob(d,mu,x,sigma)\n",
    "    p2 = prob(d,mu_p,x,sigma)\n",
    "    r = np.random.randn()\n",
    "    a =acceptance_rate(p1,p2)\n",
    "    # print(\"r {} a {}\".format(np.log(r),a))\n",
    "    if np.log(r)< a:\n",
    "        rate +=1\n",
    "        return mu_p\n",
    "    else:\n",
    "        return mu\n",
    "\n",
    "\n",
    "rate = 0\n",
    "mu_0 = [1,-1,1,-1]\n",
    "mu = [mu_0]\n",
    "#burn in\n",
    "for i in range(10000):\n",
    "    # print(mu[-1])\n",
    "    mu.append(mcmc(d,mu[-1],x,sigma))\n",
    "print(\"Burn In Done\")\n",
    "mu = [mu[-1]]\n",
    "\n",
    "data = []\n",
    "rate = 0\n",
    "for i in range(400000):\n",
    "    # print(mu[-1])\n",
    "    mu.append(mcmc(d,mu[-1],x,sigma))\n",
    "    if i % 1000 ==0:\n",
    "        data.append(mu[-1])\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "testy = l2 =[[row[i] for row in data] for i in range(len(data[0]))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  1.9801564842594683, STD DEV =  0.4237496420708027, Tue Value =  1.0, Diff =  0.9801564842594683\n",
      "Mean =  -0.8777661560707622, STD DEV =  0.5977175273827772, Tue Value =  -0.5, Diff =  0.37776615607076225\n",
      "Mean =  -0.8303407236731811, STD DEV =  1.0290813095918179, Tue Value =  1.0, Diff =  1.830340723673181\n",
      "Mean =  -3.055026348309121, STD DEV =  1.684964949495684, Tue Value =  -0.75, Diff =  2.305026348309121\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f,a = plt.subplots(len(mu_0))\n",
    "a = a.ravel()\n",
    "means = []\n",
    "stand_dev = []\n",
    "for idx,ax in enumerate(a):\n",
    "    means.append(np.mean(testy[idx]))\n",
    "    stand_dev.append(np.std(testy[idx]))\n",
    "    ax.hist(testy[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "for i in range(4):\n",
    "    print(\"Mean = \",means[i],end=', ')\n",
    "    print(\"STD DEV = \",stand_dev[i],end=', ')\n",
    "    print(\"Tue Value = \",m_t[i],end=', ')\n",
    "    print(\"Diff = \",np.abs(means[i]-m_t[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Problem ###\n",
    " How close are you to 'truth'?\n",
    " - I was not very close to the truth on all 4 variable but I seemed to be close on 2 vars with each run.\n",
    "\n",
    "Consider the following question: would it be better to double the size of the data set, or halve the errors in the data?\n",
    " - It seems to be better to lower the error in the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}